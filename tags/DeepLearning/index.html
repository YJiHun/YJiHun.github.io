<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: DeepLearning - 지훈 블로그</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="지훈 블로그"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="지훈 블로그"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="지훈 블로그"><meta property="og:url" content="https://yjihun.github.io/"><meta property="og:site_name" content="지훈 블로그"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://yjihun.github.io/img/og_image.png"><meta property="article:author" content="John Doe"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://YJiHun.github.io"},"headline":"지훈 블로그","image":["https://yjihun.github.io/img/og_image.png"],"author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"지훈 블로그","logo":{"@type":"ImageObject","url":null}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">지훈 블로그</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/YJiHun"><i class="fab fa-github"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">DeepLearning</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-10-27T08:20:00.000Z" title="2021. 10. 27. 오후 5:20:00">2021-10-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-10-27T08:23:00.000Z" title="2021. 10. 27. 오후 5:23:00">2021-10-27</time></span><span class="level-item"><a class="link-muted" href="/categories/DeepLearning/">DeepLearning</a></span><span class="level-item">8 minutes read (About 1213 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/27/DeepLearning/Fashion_Mnist_dataset/6_Fashion_Mnist_dataset/">Fashion_Minist_dataset을 이용하여 딥러닝 공부</a></h1><div class="content"><h1 id="데이터"><a href="#데이터" class="headerlink" title="데이터"></a>데이터</h1><hr>
<h2 id="1-데이터-불러오기"><a href="#1-데이터-불러오기" class="headerlink" title="1. 데이터 불러오기"></a>1. 데이터 불러오기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">x_train.shape, y_train.shape, x_test.shape, x_test.shape </span><br></pre></td></tr></table></figure>




<pre><code>((60000, 28, 28), (60000,), (10000, 28, 28), (10000, 28, 28))
</code></pre>
<h2 id="2-데이터-시각화-EDA"><a href="#2-데이터-시각화-EDA" class="headerlink" title="2. 데이터 시각화 (EDA)"></a>2. 데이터 시각화 (EDA)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>):</span><br><span class="line">  plt.subplot(<span class="number">5</span>, <span class="number">6</span>, i + <span class="number">1</span>)</span><br><span class="line">  img = x_train[i]</span><br><span class="line">  label = y_train[i]</span><br><span class="line">  plt.imshow(img, cmap= <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">  plt.title(label)</span><br><span class="line">  plt.xticks([])</span><br><span class="line">  plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_5_0.png" alt="png"></p>
<ul>
<li>이미지 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(x_train[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0
    0   1   4   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62
   54   0   0   0   1   3   4   0   0   3]
 [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134
  144 123  23   0   0   0   0  12  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178
  107 156 161 109  64  23  77 130  72  15]
 [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216
  216 163 127 121 122 146 141  88 172  66]
 [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229
  223 223 215 213 164 127 123 196 229   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228
  235 227 224 222 224 221 223 245 173   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198
  180 212 210 211 213 223 220 243 202   0]
 [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192
  169 227 208 218 224 212 226 197 209  52]
 [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203
  198 221 215 213 222 220 245 119 167  56]
 [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240
  232 213 218 223 234 217 217 209  92   0]
 [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219
  222 221 216 223 229 215 218 255  77   0]
 [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208
  211 218 224 223 219 215 224 244 159   0]
 [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230
  224 234 176 188 250 248 233 238 215   0]
 [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223
  255 255 221 234 221 211 220 232 246   0]
 [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221
  188 154 191 210 204 209 222 228 225   0]
 [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117
  168 219 221 215 217 223 223 224 229  29]
 [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245
  239 223 218 212 209 222 220 221 230  67]
 [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216
  199 206 186 181 177 172 181 205 206 115]
 [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191
  195 191 198 192 176 156 167 177 210  92]
 [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209
  210 210 211 188 188 194 192 216 170   0]
 [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179
  182 182 181 176 166 168  99  58   0   0]
 [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]]
</code></pre>
<ul>
<li><p>실제 데이터 확인</p>
</li>
<li><p>데이터 시각화</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">&#x27;Data distribution&#x27;</span>)</span><br><span class="line">plt.hist(np.reshape(x_train, (<span class="number">60000</span>*<span class="number">28</span>*<span class="number">28</span>)),log=<span class="literal">True</span>, bins=<span class="number">50</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"><span class="comment"># plt.hist(np.reshape(x_train, (1, -1)))</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_10_0.png" alt="png"></p>
<h2 id="3-데이터-전처리"><a href="#3-데이터-전처리" class="headerlink" title="3. 데이터 전처리"></a>3. 데이터 전처리</h2><ul>
<li>정규화</li>
<li>원핫벡터</li>
</ul>
<h3 id="min-max-normalization"><a href="#min-max-normalization" class="headerlink" title="min max normalization"></a><strong>min max normalization</strong></h3><h1 id="frac-x-x-min-x-max-x-min"><a href="#frac-x-x-min-x-max-x-min" class="headerlink" title="$\frac{x-x_{min}}{x_{max}-x_{min}}$"></a><center>$\frac{x-x_{min}}{x_{max}-x_{min}}$</center></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minmax</span>(<span class="params">x</span>):</span></span><br><span class="line">  x_min = np.<span class="built_in">min</span>(x)</span><br><span class="line">  x_max = np.<span class="built_in">max</span>(x)</span><br><span class="line">  <span class="comment"># print(x_min, x_max)</span></span><br><span class="line">  result = (x - x_min) / (x_max - x_min)</span><br><span class="line">  <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train_minmax = minmax(x_train)</span><br><span class="line">x_test_minmax = minmax(x_test)</span><br><span class="line"></span><br><span class="line">x_train_minmax.shape, x_test_minmax.shape</span><br></pre></td></tr></table></figure>




<pre><code>((60000, 28, 28), (10000, 28, 28))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Train data minmax normed distribution&#x27;</span>)</span><br><span class="line">plt.hist(np.reshape(x_train_minmax, (<span class="number">60000</span>*<span class="number">28</span>*<span class="number">28</span>)),log=<span class="literal">True</span>, bins=<span class="number">50</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Test data minmax normed distribution&#x27;</span>)</span><br><span class="line">plt.hist(np.reshape(x_test_minmax, (<span class="number">10000</span>*<span class="number">28</span>*<span class="number">28</span>)),log=<span class="literal">True</span>, bins=<span class="number">50</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_15_0.png" alt="png"></p>
<h3 id="Z-Score-Normalization"><a href="#Z-Score-Normalization" class="headerlink" title="Z-Score Normalization"></a><strong>Z-Score Normalization</strong></h3><h1 id="frac-x-bar-x-sigma"><a href="#frac-x-bar-x-sigma" class="headerlink" title="$\frac{x-\bar{x}}{\sigma}$"></a><center>$\frac{x-\bar{x}}{\sigma}$</center></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">z_score</span>(<span class="params">x</span>):</span></span><br><span class="line">  x_mean = np.mean(x)</span><br><span class="line">  x_std = np.std(x)</span><br><span class="line">  result = (x - x_mean) / x_std</span><br><span class="line">  <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train_z_score = z_score(x_train)</span><br><span class="line">x_test_z_score = z_score(x_test)</span><br><span class="line"></span><br><span class="line">x_train_z_score.shape, x_test_z_score.shape</span><br></pre></td></tr></table></figure>




<pre><code>((60000, 28, 28), (10000, 28, 28))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Train data minmax normed distribution&#x27;</span>)</span><br><span class="line">plt.hist(np.reshape(x_train_z_score, (<span class="number">60000</span>*<span class="number">28</span>*<span class="number">28</span>)),log=<span class="literal">True</span>, bins=<span class="number">50</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Test data minmax normed distribution&#x27;</span>)</span><br><span class="line">plt.hist(np.reshape(x_test_z_score, (<span class="number">10000</span>*<span class="number">28</span>*<span class="number">28</span>)),log=<span class="literal">True</span>, bins=<span class="number">50</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_19_0.png" alt="png"></p>
<h3 id="one-hot-coding"><a href="#one-hot-coding" class="headerlink" title="one-hot coding"></a><strong>one-hot coding</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.utils <span class="keyword">import</span> to_categorical</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_train_onehot = to_categorical(y_train, num_classes =<span class="number">10</span>)</span><br><span class="line">y_test_onehot = to_categorical(y_test, num_classes =<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">y_train_onehot.shape, y_test_onehot.shape</span><br></pre></td></tr></table></figure>




<pre><code>((60000, 10), (10000, 10))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_train_onehot</span><br></pre></td></tr></table></figure>




<pre><code>array([[0., 0., 0., ..., 0., 0., 1.],
       [1., 0., 0., ..., 0., 0., 0.],
       [1., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [1., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
</code></pre>
<h1 id="모델"><a href="#모델" class="headerlink" title="모델"></a>모델</h1><hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models, layers, optimizers</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sr = models.Sequential(name=<span class="string">&#x27;Softmax_regression&#x27;</span>)</span><br><span class="line">sr.add(layers.Flatten(input_shape=[<span class="number">28</span>, <span class="number">28</span>]))</span><br><span class="line">sr.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">sr.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;Softmax_regression&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
dense (Dense)                (None, 10)                7850      
=================================================================
Total params: 7,850
Trainable params: 7,850
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<h2 id="1-모델구현"><a href="#1-모델구현" class="headerlink" title="1. 모델구현"></a>1. 모델구현</h2><hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Softmax-regression"><a href="#Softmax-regression" class="headerlink" title="Softmax regression"></a><strong>Softmax regression</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="DNN"><a href="#DNN" class="headerlink" title="DNN"></a><strong>DNN</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DNN = models.Sequential(name=<span class="string">&#x27;DNN&#x27;</span>)</span><br><span class="line"><span class="comment">#Input layer</span></span><br><span class="line">DNN.add(layers.Flatten(input_shape=[<span class="number">28</span>, <span class="number">28</span>]))</span><br><span class="line"><span class="comment">#hidden layer</span></span><br><span class="line">DNN.add(layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">DNN.add(layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment">#output layer</span></span><br><span class="line">DNN.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">DNN.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;DNN&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 784)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 100)               78500     
_________________________________________________________________
dense_2 (Dense)              (None, 100)               10100     
_________________________________________________________________
dense_3 (Dense)              (None, 10)                1010      
=================================================================
Total params: 89,610
Trainable params: 89,610
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<h3 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a><strong>CNN</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">CNN = models.Sequential(name=<span class="string">&#x27;CNN&#x27;</span>)</span><br><span class="line"><span class="comment"># x data : (28, 28) -&gt; 2차원</span></span><br><span class="line"><span class="comment"># dense : (764) -&gt; 1차원</span></span><br><span class="line"><span class="comment"># convolution : (28, 28, 1) -&gt; 3차원</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Input layer</span></span><br><span class="line">CNN.add(layers.Reshape([<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>], input_shape=[<span class="number">28</span>, <span class="number">28</span>]))</span><br><span class="line"><span class="comment">#hidden layer</span></span><br><span class="line">CNN.add(layers.Conv2D(<span class="number">10</span>, kernel_size = <span class="number">5</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">CNN.add(layers.MaxPool2D(pool_size = <span class="number">3</span>))</span><br><span class="line">CNN.add(layers.Conv2D(<span class="number">10</span>, kernel_size = <span class="number">5</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">CNN.add(layers.MaxPool2D(pool_size = <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#output layer</span></span><br><span class="line">CNN.add(layers.Flatten())</span><br><span class="line">CNN.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">CNN.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;CNN&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
reshape (Reshape)            (None, 28, 28, 1)         0         
_________________________________________________________________
conv2d (Conv2D)              (None, 24, 24, 10)        260       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 8, 8, 10)          0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 4, 4, 10)          2510      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 1, 1, 10)          0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 10)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 10)                110       
=================================================================
Total params: 2,880
Trainable params: 2,880
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<h2 id="2-학습"><a href="#2-학습" class="headerlink" title="2. 학습"></a>2. 학습</h2><hr>
<h3 id="Softmax-Regression"><a href="#Softmax-Regression" class="headerlink" title="Softmax Regression"></a><strong>Softmax Regression</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sr.<span class="built_in">compile</span>(optimizer=optimizers.SGD(learning_rate=<span class="number">0.01</span>),</span><br><span class="line">           loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">           metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">sr.fit(x_train_minmax, y_train_onehot, epochs=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
1875/1875 [==============================] - 7s 2ms/step - loss: 0.8363 - acc: 0.7333
Epoch 2/20
1875/1875 [==============================] - 5s 2ms/step - loss: 0.5929 - acc: 0.8083
Epoch 3/20
1875/1875 [==============================] - 5s 2ms/step - loss: 0.5426 - acc: 0.8217
Epoch 4/20
1875/1875 [==============================] - 4s 2ms/step - loss: 0.5157 - acc: 0.8290
Epoch 5/20
1875/1875 [==============================] - 4s 2ms/step - loss: 0.4979 - acc: 0.8332
Epoch 6/20
1875/1875 [==============================] - 5s 2ms/step - loss: 0.4851 - acc: 0.8375
Epoch 7/20
1875/1875 [==============================] - 5s 2ms/step - loss: 0.4759 - acc: 0.8407
Epoch 8/20
1875/1875 [==============================] - 5s 2ms/step - loss: 0.4680 - acc: 0.8425
Epoch 9/20
1875/1875 [==============================] - 4s 2ms/step - loss: 0.4614 - acc: 0.8445
Epoch 10/20
1875/1875 [==============================] - 4s 2ms/step - loss: 0.4560 - acc: 0.8463
Epoch 11/20
1875/1875 [==============================] - 5s 2ms/step - loss: 0.4511 - acc: 0.8471
Epoch 12/20
1875/1875 [==============================] - 5s 2ms/step - loss: 0.4475 - acc: 0.8488
Epoch 13/20
1875/1875 [==============================] - 4s 2ms/step - loss: 0.4437 - acc: 0.8498
Epoch 14/20
1875/1875 [==============================] - 5s 2ms/step - loss: 0.4408 - acc: 0.8504
Epoch 15/20
1875/1875 [==============================] - 5s 2ms/step - loss: 0.4375 - acc: 0.8516
Epoch 16/20
1875/1875 [==============================] - 5s 2ms/step - loss: 0.4349 - acc: 0.8525
Epoch 17/20
1875/1875 [==============================] - 4s 2ms/step - loss: 0.4323 - acc: 0.8536
Epoch 18/20
1875/1875 [==============================] - 4s 2ms/step - loss: 0.4301 - acc: 0.8530
Epoch 19/20
1875/1875 [==============================] - 5s 2ms/step - loss: 0.4285 - acc: 0.8536
Epoch 20/20
1875/1875 [==============================] - 5s 2ms/step - loss: 0.4259 - acc: 0.8547





&lt;keras.callbacks.History at 0x7efffc300710&gt;
</code></pre>
<h3 id="DNN-1"><a href="#DNN-1" class="headerlink" title="DNN"></a><strong>DNN</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DNN.<span class="built_in">compile</span>(optimizer=optimizers.SGD(learning_rate=<span class="number">0.01</span>),</span><br><span class="line">           loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">           metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">DNN.fit(x_train_minmax, y_train_onehot, epochs=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.7562 - acc: 0.7513
Epoch 2/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.4967 - acc: 0.8285
Epoch 3/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.4516 - acc: 0.8424
Epoch 4/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.4235 - acc: 0.8524
Epoch 5/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.4036 - acc: 0.8583
Epoch 6/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3882 - acc: 0.8637
Epoch 7/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3738 - acc: 0.8681
Epoch 8/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3630 - acc: 0.8720
Epoch 9/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3536 - acc: 0.8753
Epoch 10/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3431 - acc: 0.8785
Epoch 11/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3352 - acc: 0.8812
Epoch 12/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3277 - acc: 0.8832
Epoch 13/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3204 - acc: 0.8855
Epoch 14/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3143 - acc: 0.8866
Epoch 15/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3086 - acc: 0.8903
Epoch 16/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3025 - acc: 0.8907
Epoch 17/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.2979 - acc: 0.8932
Epoch 18/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.2927 - acc: 0.8936
Epoch 19/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.2880 - acc: 0.8956
Epoch 20/20
1875/1875 [==============================] - 5s 3ms/step - loss: 0.2838 - acc: 0.8980





&lt;keras.callbacks.History at 0x7efffbe57710&gt;
</code></pre>
<h3 id="CNN-1"><a href="#CNN-1" class="headerlink" title="CNN"></a>CNN</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CNN.<span class="built_in">compile</span>(optimizer=optimizers.SGD(learning_rate=<span class="number">0.01</span>),</span><br><span class="line">           loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">           metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">CNN.fit(x_train_minmax, y_train_onehot, epochs=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
1875/1875 [==============================] - 34s 4ms/step - loss: 1.1147 - acc: 0.6055
Epoch 2/20
1875/1875 [==============================] - 7s 3ms/step - loss: 0.6989 - acc: 0.7430
Epoch 3/20
1875/1875 [==============================] - 7s 3ms/step - loss: 0.6344 - acc: 0.7631
Epoch 4/20
1875/1875 [==============================] - 6s 3ms/step - loss: 0.5965 - acc: 0.7770
Epoch 5/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.5700 - acc: 0.7872
Epoch 6/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.5478 - acc: 0.7989
Epoch 7/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.5295 - acc: 0.8071
Epoch 8/20
1875/1875 [==============================] - 7s 3ms/step - loss: 0.5152 - acc: 0.8119
Epoch 9/20
1875/1875 [==============================] - 7s 3ms/step - loss: 0.5025 - acc: 0.8163
Epoch 10/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.4914 - acc: 0.8212
Epoch 11/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.4820 - acc: 0.8258
Epoch 12/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.4728 - acc: 0.8275
Epoch 13/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.4653 - acc: 0.8311
Epoch 14/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.4561 - acc: 0.8336
Epoch 15/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.4469 - acc: 0.8376
Epoch 16/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.4390 - acc: 0.8407
Epoch 17/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.4311 - acc: 0.8440
Epoch 18/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.4239 - acc: 0.8462
Epoch 19/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.4185 - acc: 0.8486
Epoch 20/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.4112 - acc: 0.8516





&lt;keras.callbacks.History at 0x7efffa642850&gt;
</code></pre>
<h2 id="3-성능평가"><a href="#3-성능평가" class="headerlink" title="3. 성능평가"></a>3. 성능평가</h2><hr>
<h3 id="Softmax-Regression-1"><a href="#Softmax-Regression-1" class="headerlink" title="Softmax Regression"></a>Softmax Regression</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># evaluate : 성능 평가  test를 하고싶을때 (labels이 있는경우)</span></span><br><span class="line"><span class="comment"># predict : 값 예측을 하고싶을때 (labels이 없는경우)</span></span><br><span class="line">sr_score = sr.evaluate(x_test_minmax, y_test_onehot, verbose = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;accuracy :&quot;</span>, sr_score[<span class="number">1</span>], <span class="string">&quot;loss :&quot;</span>, sr_score[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>313/313 [==============================] - 1s 3ms/step - loss: 0.4655 - acc: 0.8365
accuracy : 0.8364999890327454 loss : 0.46547895669937134
</code></pre>
<h3 id="DNN-2"><a href="#DNN-2" class="headerlink" title="DNN"></a>DNN</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DNN_score = DNN.evaluate(x_test_minmax, y_test_onehot, verbose = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;accuracy :&quot;</span>, DNN_score[<span class="number">1</span>], <span class="string">&quot;loss :&quot;</span>, DNN_score[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>313/313 [==============================] - 1s 3ms/step - loss: 0.3544 - acc: 0.8713
accuracy : 0.8712999820709229 loss : 0.3544173538684845
</code></pre>
<h3 id="CNN-2"><a href="#CNN-2" class="headerlink" title="CNN"></a>CNN</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CNN_score = CNN.evaluate(x_test_minmax, y_test_onehot, verbose = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;accuracy :&quot;</span>, CNN_score[<span class="number">1</span>], <span class="string">&quot;loss :&quot;</span>, CNN_score[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>313/313 [==============================] - 1s 3ms/step - loss: 0.4489 - acc: 0.8395
accuracy : 0.8395000100135803 loss : 0.4489458501338959
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-10-27T08:20:00.000Z" title="2021. 10. 27. 오후 5:20:00">2021-10-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-10-27T08:23:00.000Z" title="2021. 10. 27. 오후 5:23:00">2021-10-27</time></span><span class="level-item"><a class="link-muted" href="/categories/DeepLearning/">DeepLearning</a></span><span class="level-item">8 minutes read (About 1245 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/27/DeepLearning/CIFAR_dataset/6_CIFAR_dataset/">Cifar10_dataset을 이용하여 딥러닝 공부</a></h1><div class="content"><h1 id="데이터"><a href="#데이터" class="headerlink" title="데이터"></a>데이터</h1><hr>
<h2 id="1-데이터-불러오기"><a href="#1-데이터-불러오기" class="headerlink" title="1. 데이터 불러오기"></a>1. 데이터 불러오기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()</span><br><span class="line"></span><br><span class="line">x_train.shape, y_train.shape, x_test.shape, x_test.shape </span><br></pre></td></tr></table></figure>




<pre><code>((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 32, 32, 3))
</code></pre>
<h2 id="2-데이터-시각화-EDA"><a href="#2-데이터-시각화-EDA" class="headerlink" title="2. 데이터 시각화 (EDA)"></a>2. 데이터 시각화 (EDA)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>):</span><br><span class="line">  plt.subplot(<span class="number">5</span>, <span class="number">6</span>, i + <span class="number">1</span>)</span><br><span class="line">  img = x_train[i]</span><br><span class="line">  label = y_train[i]</span><br><span class="line">  plt.imshow(img, cmap= <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">  plt.title(label)</span><br><span class="line">  plt.xticks([])</span><br><span class="line">  plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>/usr/local/lib/python3.7/dist-packages/matplotlib/text.py:1165: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison
  if s != self._text:
</code></pre>
<p><img src="output_5_1.png" alt="png"></p>
<ul>
<li>이미지 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(x_train[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[[[ 59  62  63]
  [ 43  46  45]
  [ 50  48  43]
  ...
  [158 132 108]
  [152 125 102]
  [148 124 103]]

 [[ 16  20  20]
  [  0   0   0]
  [ 18   8   0]
  ...
  [123  88  55]
  [119  83  50]
  [122  87  57]]

 [[ 25  24  21]
  [ 16   7   0]
  [ 49  27   8]
  ...
  [118  84  50]
  [120  84  50]
  [109  73  42]]

 ...

 [[208 170  96]
  [201 153  34]
  [198 161  26]
  ...
  [160 133  70]
  [ 56  31   7]
  [ 53  34  20]]

 [[180 139  96]
  [173 123  42]
  [186 144  30]
  ...
  [184 148  94]
  [ 97  62  34]
  [ 83  53  34]]

 [[177 144 116]
  [168 129  94]
  [179 142  87]
  ...
  [216 184 140]
  [151 118  84]
  [123  92  72]]]
</code></pre>
<ul>
<li><p>실제 데이터 확인</p>
</li>
<li><p>데이터 시각화</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">&#x27;Data distribution&#x27;</span>)</span><br><span class="line">plt.hist(np.reshape(x_train, (<span class="number">50000</span>*<span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span>)),log=<span class="literal">True</span>, bins=<span class="number">50</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"><span class="comment"># plt.hist(np.reshape(x_train, (1, -1)))</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_10_0.png" alt="png"></p>
<h2 id="3-데이터-전처리"><a href="#3-데이터-전처리" class="headerlink" title="3. 데이터 전처리"></a>3. 데이터 전처리</h2><ul>
<li>정규화</li>
<li>원핫벡터</li>
</ul>
<h3 id="min-max-normalization"><a href="#min-max-normalization" class="headerlink" title="min max normalization"></a><strong>min max normalization</strong></h3><h1 id="frac-x-x-min-x-max-x-min"><a href="#frac-x-x-min-x-max-x-min" class="headerlink" title="$\frac{x-x_{min}}{x_{max}-x_{min}}$"></a><center>$\frac{x-x_{min}}{x_{max}-x_{min}}$</center></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minmax</span>(<span class="params">x</span>):</span></span><br><span class="line">  x_min = np.<span class="built_in">min</span>(x)</span><br><span class="line">  x_max = np.<span class="built_in">max</span>(x)</span><br><span class="line">  <span class="comment"># print(x_min, x_max)</span></span><br><span class="line">  result = (x - x_min) / (x_max - x_min)</span><br><span class="line">  <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train_minmax = minmax(x_train)</span><br><span class="line">x_test_minmax = minmax(x_test)</span><br><span class="line"></span><br><span class="line">x_train_minmax.shape, x_test_minmax.shape</span><br></pre></td></tr></table></figure>




<pre><code>((50000, 32, 32, 3), (10000, 32, 32, 3))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Train data minmax normed distribution&#x27;</span>)</span><br><span class="line">plt.hist(np.reshape(x_train_minmax, (<span class="number">50000</span>*<span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span>)),log=<span class="literal">True</span>, bins=<span class="number">50</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Test data minmax normed distribution&#x27;</span>)</span><br><span class="line">plt.hist(np.reshape(x_test_minmax, (<span class="number">10000</span>*<span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span>)),log=<span class="literal">True</span>, bins=<span class="number">50</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_15_0.png" alt="png"></p>
<h3 id="Z-Score-Normalization"><a href="#Z-Score-Normalization" class="headerlink" title="Z-Score Normalization"></a><strong>Z-Score Normalization</strong></h3><h1 id="frac-x-bar-x-sigma"><a href="#frac-x-bar-x-sigma" class="headerlink" title="$\frac{x-\bar{x}}{\sigma}$"></a><center>$\frac{x-\bar{x}}{\sigma}$</center></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">z_score</span>(<span class="params">x</span>):</span></span><br><span class="line">  x_mean = np.mean(x)</span><br><span class="line">  x_std = np.std(x)</span><br><span class="line">  result = (x - x_mean) / x_std</span><br><span class="line">  <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train_z_score = z_score(x_train)</span><br><span class="line">x_test_z_score = z_score(x_test)</span><br><span class="line"></span><br><span class="line">x_train_z_score.shape, x_test_z_score.shape</span><br></pre></td></tr></table></figure>




<pre><code>((50000, 32, 32, 3), (10000, 32, 32, 3))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Train data minmax normed distribution&#x27;</span>)</span><br><span class="line">plt.hist(np.reshape(x_train_z_score, (<span class="number">50000</span>*<span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span>)),log=<span class="literal">True</span>, bins=<span class="number">50</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Test data minmax normed distribution&#x27;</span>)</span><br><span class="line">plt.hist(np.reshape(x_test_z_score, (<span class="number">10000</span>*<span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span>)),log=<span class="literal">True</span>, bins=<span class="number">50</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_19_0.png" alt="png"></p>
<h3 id="one-hot-coding"><a href="#one-hot-coding" class="headerlink" title="one-hot coding"></a><strong>one-hot coding</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.utils <span class="keyword">import</span> to_categorical</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_train_onehot = to_categorical(y_train, num_classes =<span class="number">10</span>)</span><br><span class="line">y_test_onehot = to_categorical(y_test, num_classes =<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">y_train_onehot.shape, y_test_onehot.shape</span><br></pre></td></tr></table></figure>




<pre><code>((50000, 10), (10000, 10))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_train_onehot</span><br></pre></td></tr></table></figure>




<pre><code>array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 1.],
       [0., 0., 0., ..., 0., 0., 1.],
       ...,
       [0., 0., 0., ..., 0., 0., 1.],
       [0., 1., 0., ..., 0., 0., 0.],
       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)
</code></pre>
<h1 id="모델"><a href="#모델" class="headerlink" title="모델"></a>모델</h1><hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models, layers, optimizers</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sr = models.Sequential(name=<span class="string">&#x27;Softmax_regression&#x27;</span>)</span><br><span class="line">sr.add(layers.Flatten(input_shape=[<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>]))</span><br><span class="line">sr.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">sr.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;Softmax_regression&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_19 (Flatten)         (None, 3072)              0         
_________________________________________________________________
dense_18 (Dense)             (None, 10)                30730     
=================================================================
Total params: 30,730
Trainable params: 30,730
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<h2 id="1-모델구현"><a href="#1-모델구현" class="headerlink" title="1. 모델구현"></a>1. 모델구현</h2><hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Softmax-regression"><a href="#Softmax-regression" class="headerlink" title="Softmax regression"></a><strong>Softmax regression</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="DNN"><a href="#DNN" class="headerlink" title="DNN"></a><strong>DNN</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DNN = models.Sequential(name=<span class="string">&#x27;DNN&#x27;</span>)</span><br><span class="line"><span class="comment">#Input layer</span></span><br><span class="line">DNN.add(layers.Flatten(input_shape=[<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>]))</span><br><span class="line"><span class="comment">#hidden layer</span></span><br><span class="line">DNN.add(layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">DNN.add(layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment">#output layer</span></span><br><span class="line">DNN.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">DNN.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;DNN&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_20 (Flatten)         (None, 3072)              0         
_________________________________________________________________
dense_19 (Dense)             (None, 100)               307300    
_________________________________________________________________
dense_20 (Dense)             (None, 100)               10100     
_________________________________________________________________
dense_21 (Dense)             (None, 10)                1010      
=================================================================
Total params: 318,410
Trainable params: 318,410
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<h3 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a><strong>CNN</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">CNN = models.Sequential(name=<span class="string">&#x27;CNN&#x27;</span>)</span><br><span class="line"><span class="comment"># x data : (28, 28) -&gt; 2차원</span></span><br><span class="line"><span class="comment"># dense : (764) -&gt; 1차원</span></span><br><span class="line"><span class="comment"># convolution : (28, 28, 1) -&gt; 3차원</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Input layer</span></span><br><span class="line">CNN.add(layers.Reshape([<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>], input_shape=[<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>]))</span><br><span class="line"><span class="comment"># CNN.add(layers.Flatten(input_shape = [32, 32, 3]))</span></span><br><span class="line"><span class="comment">#hidden layer</span></span><br><span class="line">CNN.add(layers.Conv2D(<span class="number">10</span>, kernel_size = <span class="number">5</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">CNN.add(layers.MaxPool2D(pool_size = <span class="number">3</span>))</span><br><span class="line">CNN.add(layers.Conv2D(<span class="number">10</span>, kernel_size = <span class="number">5</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">CNN.add(layers.MaxPool2D(pool_size = <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#output layer</span></span><br><span class="line">CNN.add(layers.Flatten())</span><br><span class="line">CNN.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">CNN.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;CNN&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
reshape_6 (Reshape)          (None, 32, 32, 3)         0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 28, 28, 10)        760       
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 9, 9, 10)          0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 5, 5, 10)          2510      
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 1, 1, 10)          0         
_________________________________________________________________
flatten_21 (Flatten)         (None, 10)                0         
_________________________________________________________________
dense_22 (Dense)             (None, 10)                110       
=================================================================
Total params: 3,380
Trainable params: 3,380
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<h2 id="2-학습"><a href="#2-학습" class="headerlink" title="2. 학습"></a>2. 학습</h2><hr>
<h3 id="Softmax-Regression"><a href="#Softmax-Regression" class="headerlink" title="Softmax Regression"></a><strong>Softmax Regression</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sr.<span class="built_in">compile</span>(optimizer=optimizers.SGD(learning_rate=<span class="number">0.01</span>),</span><br><span class="line">           loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">           metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">sr.fit(x_train_minmax, y_train_onehot, epochs=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
1563/1563 [==============================] - 8s 3ms/step - loss: 1.9475 - acc: 0.3043
Epoch 2/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.8404 - acc: 0.3543
Epoch 3/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.8150 - acc: 0.3650
Epoch 4/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7946 - acc: 0.3737
Epoch 5/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7831 - acc: 0.3779
Epoch 6/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7728 - acc: 0.3838
Epoch 7/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7674 - acc: 0.3821
Epoch 8/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7582 - acc: 0.3895
Epoch 9/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7522 - acc: 0.3927
Epoch 10/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7467 - acc: 0.3933
Epoch 11/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7426 - acc: 0.3962
Epoch 12/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7393 - acc: 0.3966
Epoch 13/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7319 - acc: 0.4015
Epoch 14/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7296 - acc: 0.4004
Epoch 15/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7303 - acc: 0.3997
Epoch 16/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7267 - acc: 0.4037
Epoch 17/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7242 - acc: 0.4018
Epoch 18/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7214 - acc: 0.4049
Epoch 19/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7194 - acc: 0.4059
Epoch 20/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.7161 - acc: 0.4086





&lt;keras.callbacks.History at 0x7fa6a575cb10&gt;
</code></pre>
<h3 id="DNN-1"><a href="#DNN-1" class="headerlink" title="DNN"></a><strong>DNN</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DNN.<span class="built_in">compile</span>(optimizer=optimizers.SGD(learning_rate=<span class="number">0.01</span>),</span><br><span class="line">           loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">           metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">DNN.fit(x_train_minmax, y_train_onehot, epochs=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
1563/1563 [==============================] - 6s 3ms/step - loss: 1.9164 - acc: 0.3105
Epoch 2/20
1563/1563 [==============================] - 5s 4ms/step - loss: 1.7298 - acc: 0.3856
Epoch 3/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.6466 - acc: 0.4165
Epoch 4/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.5964 - acc: 0.4329
Epoch 5/20
1563/1563 [==============================] - 5s 4ms/step - loss: 1.5514 - acc: 0.4513
Epoch 6/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.5182 - acc: 0.4627
Epoch 7/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.4865 - acc: 0.4740
Epoch 8/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.4621 - acc: 0.4831
Epoch 9/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.4402 - acc: 0.4893
Epoch 10/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.4179 - acc: 0.4969
Epoch 11/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.3974 - acc: 0.5056
Epoch 12/20
1563/1563 [==============================] - 5s 4ms/step - loss: 1.3817 - acc: 0.5103
Epoch 13/20
1563/1563 [==============================] - 5s 3ms/step - loss: 1.3635 - acc: 0.5169
Epoch 14/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.3485 - acc: 0.5206
Epoch 15/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.3333 - acc: 0.5272
Epoch 16/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.3202 - acc: 0.5307
Epoch 17/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.3058 - acc: 0.5370
Epoch 18/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.2915 - acc: 0.5434
Epoch 19/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.2782 - acc: 0.5468
Epoch 20/20
1563/1563 [==============================] - 6s 4ms/step - loss: 1.2670 - acc: 0.5487





&lt;keras.callbacks.History at 0x7fa6a72738d0&gt;
</code></pre>
<h3 id="CNN-1"><a href="#CNN-1" class="headerlink" title="CNN"></a>CNN</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CNN.<span class="built_in">compile</span>(optimizer=optimizers.SGD(learning_rate=<span class="number">0.01</span>),</span><br><span class="line">           loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">           metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">CNN.fit(x_train_minmax, y_train_onehot, epochs=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
1563/1563 [==============================] - 34s 5ms/step - loss: 2.2529 - acc: 0.1649
Epoch 2/20
1563/1563 [==============================] - 7s 4ms/step - loss: 2.0787 - acc: 0.2463
Epoch 3/20
1563/1563 [==============================] - 7s 4ms/step - loss: 1.9293 - acc: 0.2835
Epoch 4/20
1563/1563 [==============================] - 7s 5ms/step - loss: 1.8375 - acc: 0.3172
Epoch 5/20
1563/1563 [==============================] - 7s 5ms/step - loss: 1.7666 - acc: 0.3460
Epoch 6/20
1563/1563 [==============================] - 7s 5ms/step - loss: 1.6964 - acc: 0.3763
Epoch 7/20
1563/1563 [==============================] - 7s 5ms/step - loss: 1.6457 - acc: 0.3998
Epoch 8/20
1563/1563 [==============================] - 7s 5ms/step - loss: 1.6103 - acc: 0.4169
Epoch 9/20
1563/1563 [==============================] - 7s 5ms/step - loss: 1.5839 - acc: 0.4256
Epoch 10/20
1563/1563 [==============================] - 7s 4ms/step - loss: 1.5658 - acc: 0.4327
Epoch 11/20
1563/1563 [==============================] - 7s 5ms/step - loss: 1.5445 - acc: 0.4410
Epoch 12/20
1563/1563 [==============================] - 7s 4ms/step - loss: 1.5313 - acc: 0.4492
Epoch 13/20
1563/1563 [==============================] - 7s 4ms/step - loss: 1.5190 - acc: 0.4527
Epoch 14/20
1563/1563 [==============================] - 7s 4ms/step - loss: 1.5042 - acc: 0.4570
Epoch 15/20
1563/1563 [==============================] - 7s 4ms/step - loss: 1.4925 - acc: 0.4628
Epoch 16/20
1563/1563 [==============================] - 7s 4ms/step - loss: 1.4811 - acc: 0.4684
Epoch 17/20
1563/1563 [==============================] - 7s 4ms/step - loss: 1.4682 - acc: 0.4751
Epoch 18/20
1563/1563 [==============================] - 7s 4ms/step - loss: 1.4580 - acc: 0.4788
Epoch 19/20
1563/1563 [==============================] - 7s 4ms/step - loss: 1.4467 - acc: 0.4819
Epoch 20/20
1563/1563 [==============================] - 7s 4ms/step - loss: 1.4370 - acc: 0.4872





&lt;keras.callbacks.History at 0x7fa627b0a450&gt;
</code></pre>
<h2 id="3-성능평가"><a href="#3-성능평가" class="headerlink" title="3. 성능평가"></a>3. 성능평가</h2><hr>
<h3 id="Softmax-Regression-1"><a href="#Softmax-Regression-1" class="headerlink" title="Softmax Regression"></a>Softmax Regression</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># evaluate : 성능 평가  test를 하고싶을때 (labels이 있는경우)</span></span><br><span class="line"><span class="comment"># predict : 값 예측을 하고싶을때 (labels이 없는경우)</span></span><br><span class="line">sr_score = sr.evaluate(x_test_minmax, y_test_onehot, verbose = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;accuracy :&quot;</span>, sr_score[<span class="number">1</span>], <span class="string">&quot;loss :&quot;</span>, sr_score[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>313/313 [==============================] - 1s 3ms/step - loss: 1.8597 - acc: 0.3399
accuracy : 0.3398999869823456 loss : 1.8596729040145874
</code></pre>
<h3 id="DNN-2"><a href="#DNN-2" class="headerlink" title="DNN"></a>DNN</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DNN_score = DNN.evaluate(x_test_minmax, y_test_onehot, verbose = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;accuracy :&quot;</span>, DNN_score[<span class="number">1</span>], <span class="string">&quot;loss :&quot;</span>, DNN_score[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>313/313 [==============================] - 1s 3ms/step - loss: 1.4524 - acc: 0.4859
accuracy : 0.48590001463890076 loss : 1.4524061679840088
</code></pre>
<h3 id="CNN-2"><a href="#CNN-2" class="headerlink" title="CNN"></a>CNN</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CNN_score = CNN.evaluate(x_test_minmax, y_test_onehot, verbose = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;accuracy :&quot;</span>, CNN_score[<span class="number">1</span>], <span class="string">&quot;loss :&quot;</span>, CNN_score[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>313/313 [==============================] - 1s 4ms/step - loss: 1.4791 - acc: 0.4728
accuracy : 0.47279998660087585 loss : 1.4790728092193604
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-10-27T08:20:00.000Z" title="2021. 10. 27. 오후 5:20:00">2021-10-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-10-27T08:23:00.000Z" title="2021. 10. 27. 오후 5:23:00">2021-10-27</time></span><span class="level-item"><a class="link-muted" href="/categories/DeepLearning/">DeepLearning</a></span><span class="level-item">7 minutes read (About 1081 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/27/DeepLearning/Iris_dataset/%EA%B3%BC%EC%A0%9C1_Iris_dataset(%EC%A2%85%EB%A5%98%20%EC%98%88%EC%B8%A1)/">Iris_dataset을 이용하여 딥러닝 공부</a></h1><div class="content"><h2 id="1-데이터-정의"><a href="#1-데이터-정의" class="headerlink" title="1. 데이터 정의"></a>1. 데이터 정의</h2><hr>
<ul>
<li>sklearn 으로 부터 iris 데이터셋을 불러옵니다.</li>
<li>x_data와 y_data를 정의합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">! ls</span><br></pre></td></tr></table></figure>

<pre><code>iris_test.csv  iris_train.csv  sample_data  sample_submission.csv
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_data = pd.read_csv(<span class="string">&#x27;iris_test.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data = pd.read_csv(<span class="string">&#x27;iris_train.csv&#x27;</span>)</span><br><span class="line">train_data</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>species</th>
      <th>sepal length (cm)</th>
      <th>petal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal width (cm)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>setosa</td>
      <td>4.4</td>
      <td>1.4</td>
      <td>2.9</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>versicolor</td>
      <td>6.4</td>
      <td>4.5</td>
      <td>3.2</td>
      <td>1.5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>virginica</td>
      <td>6.2</td>
      <td>4.8</td>
      <td>2.8</td>
      <td>1.8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>virginica</td>
      <td>7.2</td>
      <td>6.1</td>
      <td>3.6</td>
      <td>2.5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>setosa</td>
      <td>4.9</td>
      <td>1.4</td>
      <td>3.0</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>70</th>
      <td>70</td>
      <td>versicolor</td>
      <td>6.5</td>
      <td>4.6</td>
      <td>2.8</td>
      <td>1.5</td>
    </tr>
    <tr>
      <th>71</th>
      <td>71</td>
      <td>versicolor</td>
      <td>5.6</td>
      <td>3.6</td>
      <td>2.9</td>
      <td>1.3</td>
    </tr>
    <tr>
      <th>72</th>
      <td>72</td>
      <td>versicolor</td>
      <td>6.2</td>
      <td>4.5</td>
      <td>2.2</td>
      <td>1.5</td>
    </tr>
    <tr>
      <th>73</th>
      <td>73</td>
      <td>versicolor</td>
      <td>4.9</td>
      <td>3.3</td>
      <td>2.4</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>74</th>
      <td>74</td>
      <td>versicolor</td>
      <td>6.9</td>
      <td>4.9</td>
      <td>3.1</td>
      <td>1.5</td>
    </tr>
  </tbody>
</table>
<p>75 rows × 6 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data_np = train_data.to_numpy()</span><br><span class="line"></span><br><span class="line">x_data = data_np[:, <span class="number">2</span>:].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">y_data = data_np[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x_data.shape)</span><br><span class="line"><span class="built_in">print</span>(y_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(75, 4)
(75,)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_data</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_data</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &#x27;setosa&#x27; = 0</span></span><br><span class="line"><span class="comment"># &#x27;versicolor&#x27; = 1</span></span><br><span class="line"><span class="comment"># &#x27;virginica&#x27; = 2</span></span><br><span class="line">kind = train_data[<span class="string">&#x27;species&#x27;</span>].drop_duplicates().to_numpy() <span class="comment"># 꽃 종류</span></span><br><span class="line">kind</span><br></pre></td></tr></table></figure>




<pre><code>array([&#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39;], dtype=object)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 꽃 종류 숫자 변환</span></span><br><span class="line"><span class="keyword">for</span> num, name <span class="keyword">in</span> <span class="built_in">enumerate</span>(kind):</span><br><span class="line">  y_data[y_data == name] = num</span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(y_data, <span class="built_in">type</span>(y_data)) </span><br></pre></td></tr></table></figure>

<pre><code>[0 1 2 2 0 2 0 1 1 1 1 2 1 0 0 2 2 2 0 1 1 0 1 2 2 2 2 2 2 2 1 0 2 2 2 2 2
 0 1 1 1 2 1 0 2 1 1 1 1 1 0 1 0 1 0 1 2 0 2 2 2 2 2 2 0 2 1 1 1 2 1 1 1 1
 1] &lt;class &#39;numpy.ndarray&#39;&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &#x27;setosa&#x27; = 0</span></span><br><span class="line"><span class="comment"># &#x27;versicolor&#x27; = 1</span></span><br><span class="line"><span class="comment"># &#x27;virginica&#x27; = 2</span></span><br><span class="line">kind_index = <span class="number">0</span></span><br><span class="line"><span class="built_in">print</span>(x_data[y_data == kind_index])</span><br></pre></td></tr></table></figure>

<pre><code>[[4.4 1.4 2.9 0.2]
 [4.9 1.4 3.  0.2]
 [4.3 1.1 3.  0.1]
 [4.6 1.5 3.1 0.2]
 [5.8 1.2 4.  0.2]
 [5.1 1.4 3.5 0.2]
 [5.4 1.7 3.9 0.4]
 [5.  1.5 3.4 0.2]
 [4.9 1.5 3.1 0.1]
 [4.7 1.3 3.2 0.2]
 [4.6 1.4 3.4 0.3]
 [5.  1.4 3.6 0.2]
 [5.4 1.5 3.7 0.2]
 [4.8 1.4 3.  0.1]
 [4.8 1.6 3.4 0.2]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &#x27;setosa&#x27; = 0</span></span><br><span class="line"><span class="comment"># &#x27;versicolor&#x27; = 1</span></span><br><span class="line"><span class="comment"># &#x27;virginica&#x27; = 2</span></span><br><span class="line">kind_index = <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(x_data[y_data == kind_index])</span><br></pre></td></tr></table></figure>

<pre><code>[[6.4 4.5 3.2 1.5]
 [6.7 5.  3.  1.7]
 [6.8 4.8 2.8 1.4]
 [6.6 4.4 3.  1.4]
 [5.  3.5 2.  1. ]
 [6.3 4.7 3.3 1.6]
 [6.7 4.4 3.1 1.4]
 [5.5 4.  2.3 1.3]
 [5.2 3.9 2.7 1.4]
 [6.4 4.3 2.9 1.3]
 [5.6 3.9 2.5 1.1]
 [5.8 4.1 2.7 1. ]
 [5.9 4.2 3.  1.5]
 [6.  4.5 2.9 1.5]
 [6.3 4.9 2.5 1.5]
 [6.1 4.  2.8 1.3]
 [6.1 4.7 2.8 1.2]
 [5.7 4.5 2.8 1.3]
 [6.6 4.6 2.9 1.3]
 [6.1 4.7 2.9 1.4]
 [6.  4.  2.2 1. ]
 [5.9 4.8 3.2 1.8]
 [7.  4.7 3.2 1.4]
 [5.6 4.5 3.  1.5]
 [5.7 3.5 2.6 1. ]
 [6.5 4.6 2.8 1.5]
 [5.6 3.6 2.9 1.3]
 [6.2 4.5 2.2 1.5]
 [4.9 3.3 2.4 1. ]
 [6.9 4.9 3.1 1.5]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &#x27;setosa&#x27; = 0</span></span><br><span class="line"><span class="comment"># &#x27;versicolor&#x27; = 1</span></span><br><span class="line"><span class="comment"># &#x27;virginica&#x27; = 2</span></span><br><span class="line">kind_index = <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(x_data[y_data == kind_index])</span><br></pre></td></tr></table></figure>

<pre><code>[[6.2 4.8 2.8 1.8]
 [7.2 6.1 3.6 2.5]
 [6.5 5.8 3.  2.2]
 [6.3 4.9 2.7 1.8]
 [7.6 6.6 3.  2.1]
 [7.7 6.9 2.6 2.3]
 [7.1 5.9 3.  2.1]
 [6.  5.  2.2 1.5]
 [6.8 5.5 3.  2.1]
 [7.3 6.3 2.9 1.8]
 [6.9 5.7 3.2 2.3]
 [4.9 4.5 2.5 1.7]
 [6.4 5.6 2.8 2.1]
 [7.7 6.7 3.8 2.2]
 [6.3 6.  3.3 2.5]
 [6.7 5.8 2.5 1.8]
 [6.5 5.1 3.2 2. ]
 [7.7 6.7 2.8 2. ]
 [7.2 6.  3.2 1.8]
 [6.4 5.3 2.7 1.9]
 [6.3 5.6 2.9 1.8]
 [6.7 5.7 3.3 2.1]
 [6.5 5.5 3.  1.8]
 [6.4 5.3 3.2 2.3]
 [5.6 4.9 2.8 2. ]
 [5.8 5.1 2.8 2.4]
 [7.2 5.8 3.  1.6]
 [5.8 5.1 2.7 1.9]
 [6.1 4.9 3.  1.8]
 [5.7 5.  2.5 2. ]]
</code></pre>
<h2 id="2-데이터-시각화"><a href="#2-데이터-시각화" class="headerlink" title="2. 데이터 시각화"></a>2. 데이터 시각화</h2><hr>
<ul>
<li>데이터를 matplotlib.pyplot 라이브러리를 이용항 시각화 합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &#x27;setosa&#x27; = 0</span></span><br><span class="line"><span class="comment"># &#x27;versicolor&#x27; = 1</span></span><br><span class="line"><span class="comment"># &#x27;virginica&#x27; = 2</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x_data.shape)</span><br><span class="line"><span class="built_in">print</span>(y_data.shape)</span><br><span class="line">plt.bar(x_data[y_data == <span class="number">0</span>, <span class="number">0</span>], x_data[y_data == <span class="number">0</span>, <span class="number">2</span>], width= <span class="number">0.1</span>, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.bar(x_data[y_data == <span class="number">1</span>, <span class="number">0</span>], x_data[y_data == <span class="number">1</span>, <span class="number">2</span>], width= <span class="number">0.1</span>, color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.bar(x_data[y_data == <span class="number">2</span>, <span class="number">0</span>], x_data[y_data == <span class="number">2</span>, <span class="number">2</span>], width= <span class="number">0.1</span>, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.legend(kind)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.bar(x_data[y_data == <span class="number">0</span>, <span class="number">1</span>], x_data[y_data == <span class="number">0</span>, <span class="number">3</span>], width= <span class="number">0.1</span>, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.bar(x_data[y_data == <span class="number">1</span>, <span class="number">1</span>], x_data[y_data == <span class="number">1</span>, <span class="number">3</span>], width= <span class="number">0.1</span>, color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.bar(x_data[y_data == <span class="number">2</span>, <span class="number">1</span>], x_data[y_data == <span class="number">2</span>, <span class="number">3</span>], width= <span class="number">0.1</span>, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.legend(kind)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>(75, 4)
(75,)
</code></pre>
<p><img src="output_15_1.png" alt="png"></p>
<p><img src="output_15_2.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(y_data, marker=<span class="string">&#x27;o&#x27;</span>, linestyle=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_16_0.png" alt="png"></p>
<h2 id="3-데이터-전처리"><a href="#3-데이터-전처리" class="headerlink" title="3. 데이터 전처리"></a>3. 데이터 전처리</h2><hr>
<ul>
<li>y 데이터 값을 원-핫 벡터로 코딩합니다.</li>
<li>학습데이터와 테스트데이터를 분리합니다. <ul>
<li>sklearn.model_selection에서 제공하는 train_test_split 를 사용합니다.</li>
</ul>
</li>
</ul>
<h3 id="One-hot-코딩"><a href="#One-hot-코딩" class="headerlink" title="One-hot 코딩"></a><strong>One-hot 코딩</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(kind)</span><br><span class="line"><span class="comment"># x_data</span></span><br><span class="line"><span class="comment"># y_data</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># &#x27;setosa&#x27; = 0</span></span><br><span class="line"><span class="comment"># &#x27;versicolor&#x27; = 1</span></span><br><span class="line"><span class="comment"># &#x27;virginica&#x27; = 2</span></span><br></pre></td></tr></table></figure>

<pre><code>[&#39;setosa&#39; &#39;versicolor&#39; &#39;virginica&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line">Y_onehot = to_categorical(y_data, num_classes=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">Y_onehot.shape</span><br></pre></td></tr></table></figure>




<pre><code>(75, 3)
</code></pre>
<h3 id="train-test-split"><a href="#train-test-split" class="headerlink" title="train-test split"></a><strong>train-test split</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x_train, x_test, y_train, y_test = train_test_split(x_data, Y_onehot, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x_train.shape)</span><br><span class="line"><span class="built_in">print</span>(y_train.shape)</span><br><span class="line"><span class="built_in">print</span>(x_test.shape)</span><br><span class="line"><span class="built_in">print</span>(y_test.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>(60, 4)
(60, 3)
(15, 4)
(15, 3)
</code></pre>
<h2 id="4-모델학습"><a href="#4-모델학습" class="headerlink" title="4. 모델학습"></a>4. 모델학습</h2><hr>
<ul>
<li>softmax regression을 사용하여 훈련하고, 테스트셋을 이용해 성능을 평가합니다.</li>
<li>decision tree를 사용하여 훈련하고, 테스트셋을 이용해 성능을 평가합니다.</li>
<li>이 데이터셋에 적합한 세번째 모델을 찾아보고 훈련해 봅니다.</li>
</ul>
<h3 id="Softmax-regression"><a href="#Softmax-regression" class="headerlink" title="Softmax regression"></a><strong>Softmax regression</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> optimizers</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"></span><br><span class="line">model.add(Dense(<span class="number">3</span>, input_dim = <span class="number">4</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_6&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_6 (Dense)              (None, 3)                 15        
=================================================================
Total params: 15
Trainable params: 15
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">W = model.get_weights()[<span class="number">0</span>]</span><br><span class="line">b = model.get_weights()[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;W&#x27;</span>, W)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b&#x27;</span>, b)</span><br></pre></td></tr></table></figure>

<pre><code>W [[-0.34640932  0.649112   -0.27851325]
 [ 0.44380236 -0.80450916  0.43582928]
 [ 0.7131357  -0.1360429  -0.01573229]
 [ 0.630263    0.618158    0.3201201 ]]
b [0. 0. 0.]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=optimizers.SGD(learning_rate=<span class="number">0.01</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(x_train, y_train, epochs=<span class="number">500</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(history.history[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>], loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;loss&#x27;</span>], loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_31_0.png" alt="png"></p>
<p><img src="output_31_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">score = model.evaluate(x_test, y_test, verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:5 out of the last 5 calls to &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x7f1c42c01dd0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
1/1 [==============================] - 0s 114ms/step - loss: 0.3461 - acc: 1.0000
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;accuracy :&quot;</span>, score[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<pre><code>accuracy : 1.0
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;loss :&quot;</span>, score[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>loss : 0.3460531234741211
</code></pre>
<h3 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a><strong>Decision Tree</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dt = tree.DecisionTreeClassifier()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dt.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion=&#39;gini&#39;,
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=&#39;deprecated&#39;,
                       random_state=None, splitter=&#39;best&#39;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dt.score(x_test, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>1.0
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tree.plot_tree(dt)</span><br></pre></td></tr></table></figure>




<pre><code>[Text(152.1818181818182, 199.32, &#39;X[3] &lt;= 1.55\ngini = 0.422\nsamples = 60\nvalue = [[49, 11]\n[35, 25]\n[36, 24]]&#39;),
 Text(60.872727272727275, 163.07999999999998, &#39;X[1] &lt;= 2.5\ngini = 0.312\nsamples = 35\nvalue = [[24, 11]\n[12, 23]\n[34, 1]]&#39;),
 Text(30.436363636363637, 126.83999999999999, &#39;gini = 0.0\nsamples = 11\nvalue = [[0, 11]\n[11, 0]\n[11, 0]]&#39;),
 Text(91.30909090909091, 126.83999999999999, &#39;X[1] &lt;= 4.95\ngini = 0.053\nsamples = 24\nvalue = [[24, 0]\n[1, 23]\n[23, 1]]&#39;),
 Text(60.872727272727275, 90.6, &#39;gini = 0.0\nsamples = 23\nvalue = [[23, 0]\n[0, 23]\n[23, 0]]&#39;),
 Text(121.74545454545455, 90.6, &#39;gini = 0.0\nsamples = 1\nvalue = [[1, 0]\n[1, 0]\n[0, 1]]&#39;),
 Text(243.4909090909091, 163.07999999999998, &#39;X[1] &lt;= 5.15\ngini = 0.098\nsamples = 25\nvalue = [[25, 0]\n[23, 2]\n[2, 23]]&#39;),
 Text(213.05454545454546, 126.83999999999999, &#39;X[2] &lt;= 2.9\ngini = 0.272\nsamples = 7\nvalue = [[7, 0]\n[5, 2]\n[2, 5]]&#39;),
 Text(182.61818181818182, 90.6, &#39;gini = 0.0\nsamples = 4\nvalue = [[4, 0]\n[4, 0]\n[0, 4]]&#39;),
 Text(243.4909090909091, 90.6, &#39;X[3] &lt;= 1.75\ngini = 0.296\nsamples = 3\nvalue = [[3, 0]\n[1, 2]\n[2, 1]]&#39;),
 Text(213.05454545454546, 54.359999999999985, &#39;gini = 0.0\nsamples = 1\nvalue = [[1, 0]\n[0, 1]\n[1, 0]]&#39;),
 Text(273.92727272727274, 54.359999999999985, &#39;X[0] &lt;= 6.0\ngini = 0.333\nsamples = 2\nvalue = [[2, 0]\n[1, 1]\n[1, 1]]&#39;),
 Text(243.4909090909091, 18.119999999999976, &#39;gini = 0.0\nsamples = 1\nvalue = [[1, 0]\n[0, 1]\n[1, 0]]&#39;),
 Text(304.3636363636364, 18.119999999999976, &#39;gini = 0.0\nsamples = 1\nvalue = [[1, 0]\n[1, 0]\n[0, 1]]&#39;),
 Text(273.92727272727274, 126.83999999999999, &#39;gini = 0.0\nsamples = 18\nvalue = [[18, 0]\n[18, 0]\n[0, 18]]&#39;)]
</code></pre>
<p><img src="output_40_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="내가찾은모델"><a href="#내가찾은모델" class="headerlink" title="내가찾은모델"></a><strong>내가찾은모델</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="5-모델-비교"><a href="#5-모델-비교" class="headerlink" title="5. 모델 비교"></a>5. 모델 비교</h2><hr>
<ul>
<li>어떤 모델이 가장 좋은지 간략히 브리핑 합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-10-27T03:20:00.000Z" title="2021. 10. 27. 오후 12:20:00">2021-10-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-10-27T08:24:28.000Z" title="2021. 10. 27. 오후 5:24:28">2021-10-27</time></span><span class="level-item"><a class="link-muted" href="/categories/DeepLearning/">DeepLearning</a></span><span class="level-item">6 minutes read (About 943 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/27/DeepLearning/LogisticRegression/2_LogisticRegression/">딥러닝 공부를 해보자</a></h1><div class="content"><p><a href="https://colab.research.google.com/github/yebiny/Lecture_deeplearning_basic/blob/main/2_LogisticRegression.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<h1 id="로지스틱-회귀-Logistic-Regression"><a href="#로지스틱-회귀-Logistic-Regression" class="headerlink" title="로지스틱 회귀 ( Logistic Regression )"></a>로지스틱 회귀 ( Logistic Regression )</h1><blockquote>
<p><strong>목차</strong></p>
</blockquote>
<ol>
<li>개념정리</li>
<li>손실함수 : 크로스 엔트로피 (Cross Entropy)</li>
<li>실습</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> optimizers</span><br></pre></td></tr></table></figure>

<h2 id="1-개념정리"><a href="#1-개념정리" class="headerlink" title="1. 개념정리"></a>1. 개념정리</h2><hr>
<br>

<p>###<center> &lt; 가설 &gt; </center></p>
<h3 id="f-x-sigma-xW-b"><a href="#f-x-sigma-xW-b" class="headerlink" title="$f(x)=\sigma(xW+b)$"></a><center>$f(x)=\sigma(xW+b)$</center></h3><br>

<h3 id="lt-목적-gt"><a href="#lt-목적-gt" class="headerlink" title=" &lt; 목적 &gt; "></a><center> &lt; 목적 &gt; </center></h3><h3 id="w-b-arg-min-J-y-hat-y"><a href="#w-b-arg-min-J-y-hat-y" class="headerlink" title="$(w^{}, b^{})=arg ; min ;J(y, \hat{y})$"></a><center>$(w^{<em>}, b^{</em>})=arg ; min ;J(y, \hat{y})$</center></h3><h3 id="arg-min-J-y-f-x"><a href="#arg-min-J-y-f-x" class="headerlink" title=" $ =arg ; min ;J(y, f(x))$"></a><center> $ =arg ; min ;J(y, f(x))$</center></h3><h3 id="arg-min-J-y-sigma-xW-b"><a href="#arg-min-J-y-sigma-xW-b" class="headerlink" title=" $ =arg ; min ;J(y, \sigma(xW+b))$"></a><center> $ =arg ; min ;J(y, \sigma(xW+b))$</center></h3><h3 id="시그모이드-함수-Sigmoid-funtion"><a href="#시그모이드-함수-Sigmoid-funtion" class="headerlink" title="시그모이드 함수 ( Sigmoid funtion )"></a><strong>시그모이드 함수 ( Sigmoid funtion )</strong></h3></br>

<h3 id="H-x-frac-1-1-e-x-sigma-x"><a href="#H-x-frac-1-1-e-x-sigma-x" class="headerlink" title="$H(x) = \frac{1}{1+e^{(-x)}} = \sigma(x)$"></a><center>$H(x) = \frac{1}{1+e^{(-x)}} = \sigma(x)$</center></h3><p><strong><center> e(e=2.718281..):</strong>  자연 상수</p>
<ul>
<li>구현</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">x</span>):</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br></pre></td></tr></table></figure>

<ul>
<li>시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x_arr = np.arange(-<span class="number">5</span>, <span class="number">5</span> , <span class="number">0.1</span>)</span><br><span class="line">y_arr = []</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> x_arr:</span><br><span class="line">  y = sigmoid(x)</span><br><span class="line">  y_arr.append(y)</span><br><span class="line"></span><br><span class="line">y_arr = np.array(y_arr)</span><br><span class="line"></span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>],linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.plot(x_arr, y_arr)</span><br></pre></td></tr></table></figure>




<pre><code>[&lt;matplotlib.lines.Line2D at 0x7fd45be78b10&gt;]
</code></pre>
<p><img src="output_8_1.png" alt="png"></p>
<h3 id="가설-구현"><a href="#가설-구현" class="headerlink" title="가설 구현"></a><strong>가설 구현</strong></h3><p>###<center>$f(x)=\sigma(xW+b)$</center></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hypothesis</span>(<span class="params">x, W, b=<span class="number">0</span></span>):</span></span><br><span class="line">  <span class="keyword">return</span> sigmoid(np.dot(x,W)+b)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="예제"><a href="#예제" class="headerlink" title="예제"></a><strong>예제</strong></h3><table>
<thead>
<tr>
<th>라운드점수(X)</th>
<th>종합점수</th>
<th>결과(Y)</th>
</tr>
</thead>
<tbody><tr>
<td>-3</td>
<td>1</td>
<td>패배</td>
</tr>
<tr>
<td>-2</td>
<td>1</td>
<td>패배</td>
</tr>
<tr>
<td>-1</td>
<td>2</td>
<td>패배</td>
</tr>
<tr>
<td>0</td>
<td>3</td>
<td>패배</td>
</tr>
<tr>
<td>1</td>
<td>5</td>
<td>승리</td>
</tr>
<tr>
<td>2</td>
<td>8</td>
<td>승리</td>
</tr>
<tr>
<td>3</td>
<td>9</td>
<td>승리</td>
</tr>
</tbody></table>
<ul>
<li>데이터 정의</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X = np.arange(-<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">Y = np.array([[<span class="number">0</span>],</span><br><span class="line">              [<span class="number">0</span>],</span><br><span class="line">              [<span class="number">0</span>],</span><br><span class="line">              [<span class="number">0</span>],</span><br><span class="line">              [<span class="number">1</span>],</span><br><span class="line">              [<span class="number">1</span>],</span><br><span class="line">              [<span class="number">1</span>]])</span><br><span class="line">X[<span class="number">0</span>].shape, Y[<span class="number">0</span>].shape</span><br></pre></td></tr></table></figure>




<pre><code>((1,), (1,))
</code></pre>
<ul>
<li>예측</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">W = np.array([[<span class="number">1</span>]])</span><br><span class="line">W.shape</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> X:</span><br><span class="line">  y_pred = hypothesis(x[<span class="number">0</span>], W)</span><br><span class="line">  <span class="built_in">print</span>(y_pred)</span><br></pre></td></tr></table></figure>

<pre><code>[[0.04742587]]
[[0.11920292]]
[[0.26894142]]
[[0.5]]
[[0.73105858]]
[[0.88079708]]
[[0.95257413]]
</code></pre>
<ul>
<li>시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(X, Y, marker=<span class="string">&#x27;o&#x27;</span>, linestyle=<span class="string">&#x27;&#x27;</span>, color=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.plot(X, [hypothesis(x,W) <span class="keyword">for</span> x <span class="keyword">in</span> X], color=<span class="string">&#x27;g&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>[&lt;matplotlib.lines.Line2D at 0x7fd45c03a4d0&gt;]
</code></pre>
<p><img src="output_18_1.png" alt="png"></p>
<h3 id="학습-파라미터"><a href="#학습-파라미터" class="headerlink" title="학습 파라미터"></a><strong>학습 파라미터</strong></h3><ul>
<li>W 값에 따른 함수의 변화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(X, Y, marker=<span class="string">&#x27;o&#x27;</span>, linestyle=<span class="string">&#x27;&#x27;</span>, color=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">W = np.array([[<span class="number">0.5</span>]])</span><br><span class="line">plt.plot(X, [hypothesis(x,W) <span class="keyword">for</span> x <span class="keyword">in</span> X], color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">W = np.array([[<span class="number">1</span>]])</span><br><span class="line">plt.plot(X, [hypothesis(x,W) <span class="keyword">for</span> x <span class="keyword">in</span> X], color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">W = np.array([[<span class="number">2</span>]])</span><br><span class="line">plt.plot(X, [hypothesis(x,W) <span class="keyword">for</span> x <span class="keyword">in</span> X], color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.legend([<span class="string">&#x27;data&#x27;</span>,<span class="string">&#x27;w=0.5&#x27;</span>,<span class="string">&#x27;w=1.0&#x27;</span>,<span class="string">&#x27;w=2.0&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_21_0.png" alt="png"></p>
<ul>
<li>b값에 따른 함수의 변화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(X, Y, marker=<span class="string">&#x27;o&#x27;</span>, linestyle=<span class="string">&#x27;&#x27;</span>, color=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">W = np.array([[<span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line">b = -<span class="number">1</span></span><br><span class="line">plt.plot(X, [hypothesis(x,W,b) <span class="keyword">for</span> x <span class="keyword">in</span> X], color=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">b = <span class="number">0</span></span><br><span class="line">plt.plot(X, [hypothesis(x,W,b) <span class="keyword">for</span> x <span class="keyword">in</span> X], color=<span class="string">&#x27;g&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">b = <span class="number">1</span></span><br><span class="line">plt.plot(X, [hypothesis(x,W,b) <span class="keyword">for</span> x <span class="keyword">in</span> X], color=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.legend([<span class="string">&#x27;data&#x27;</span>,<span class="string">&#x27;b=-1&#x27;</span>,<span class="string">&#x27;b=0&#x27;</span>,<span class="string">&#x27;b=1&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_23_0.png" alt="png"></p>
<h2 id="2-손실함수-크로스-엔트로피-Cross-Entropy"><a href="#2-손실함수-크로스-엔트로피-Cross-Entropy" class="headerlink" title="2. 손실함수: 크로스 엔트로피 (Cross Entropy)"></a>2. 손실함수: 크로스 엔트로피 (Cross Entropy)</h2><hr>
</br>

<h2 id="J-W-frac-1-n-sum-i-1-n-y-i-log-hat-y-i-1-y-i-log-1-hat-y-i"><a href="#J-W-frac-1-n-sum-i-1-n-y-i-log-hat-y-i-1-y-i-log-1-hat-y-i" class="headerlink" title="$J(W) = -\frac{1}{n}\sum_{i=1}^{n}[y^{(i)}log(\hat{y}^{(i)})+(1-y^{(i)})log(1-\hat{y}^{(i)})]$"></a><center>$J(W) = -\frac{1}{n}\sum_{i=1}^{n}[y^{(i)}log(\hat{y}^{(i)})+(1-y^{(i)})log(1-\hat{y}^{(i)})]$</center></h2></br>

<center> $y = 1 \rightarrow cost(y, \hat{y}) = -log(\hat{y})$</center>
<center> $y = 0 \rightarrow cost(y, \hat{y}) = -log(1-\hat{y})$</center>


<ul>
<li>구현</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">J</span>(<span class="params">y, y_pred</span>):</span></span><br><span class="line">  <span class="keyword">if</span> y == <span class="number">1</span>:</span><br><span class="line">    <span class="keyword">return</span> -(np.log10(y_pred))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">elif</span> y == <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">return</span> -(np.log10(<span class="number">1</span>-y_pred))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">y_pred_arr = np.arange(<span class="number">0.1</span>, <span class="number">1</span>, <span class="number">0.1</span>)</span><br><span class="line"><span class="keyword">for</span> y_pred <span class="keyword">in</span> y_pred_arr:</span><br><span class="line">  plt.plot(y_pred, J(<span class="number">1</span>, y_pred), marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">  plt.plot(y_pred, J(<span class="number">0</span>, y_pred), marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.legend([<span class="string">&#x27;y = 1&#x27;</span>, <span class="string">&#x27;y = 0&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;y_pred&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss = J(y, y_pred)&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_28_0.png" alt="png"></p>
<h2 id="3-실습"><a href="#3-실습" class="headerlink" title="3. 실습"></a>3. 실습</h2><hr>
<h3 id="데이터"><a href="#데이터" class="headerlink" title="데이터"></a><strong>데이터</strong></h3><table>
<thead>
<tr>
<th>공부시간</th>
<th>집중도</th>
<th>수면시간</th>
<th>종합성적</th>
<th>합격여부</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>1</td>
<td>9</td>
<td>0</td>
<td>불합격</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>8.5</td>
<td>1.1</td>
<td>불합격</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>8</td>
<td>2.3</td>
<td>불합격</td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>8</td>
<td>3.0</td>
<td>불합격</td>
</tr>
<tr>
<td>4</td>
<td>3</td>
<td>7</td>
<td>4.4</td>
<td>불합격</td>
</tr>
<tr>
<td>5</td>
<td>5</td>
<td>7.5</td>
<td>5.5</td>
<td>합격</td>
</tr>
<tr>
<td>6</td>
<td>6</td>
<td>7</td>
<td>6.1</td>
<td>합격</td>
</tr>
<tr>
<td>7</td>
<td>6</td>
<td>6</td>
<td>7.3</td>
<td>합격</td>
</tr>
<tr>
<td>8</td>
<td>7</td>
<td>7</td>
<td>8.4</td>
<td>합격</td>
</tr>
<tr>
<td>9</td>
<td>6</td>
<td>6.5</td>
<td>9.8</td>
<td>합격</td>
</tr>
</tbody></table>
<ul>
<li>데이터 정의</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">X = np.array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">0</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">1</span>, <span class="number">8.5</span>, <span class="number">1.1</span>],</span><br><span class="line">              [<span class="number">2</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">2.3</span>],</span><br><span class="line">              [<span class="number">3</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">3.0</span>],</span><br><span class="line">              [<span class="number">4</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">4.4</span>],</span><br><span class="line">              [<span class="number">5</span>, <span class="number">5</span>, <span class="number">7.5</span>, <span class="number">5.5</span>],</span><br><span class="line">              [<span class="number">6</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">6.1</span>],</span><br><span class="line">              [<span class="number">7</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">7.3</span>],</span><br><span class="line">              [<span class="number">8</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">8.4</span>],</span><br><span class="line">              [<span class="number">9</span>, <span class="number">6</span>, <span class="number">6.5</span>, <span class="number">9.8</span>]])</span><br><span class="line">Y = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<ul>
<li>시각화 </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(Y, linestyle=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>[&lt;matplotlib.lines.Line2D at 0x7fd46055cad0&gt;]
</code></pre>
<p><img src="output_35_1.png" alt="png"></p>
<h3 id="모델-생성"><a href="#모델-생성" class="headerlink" title="모델 생성"></a><strong>모델 생성</strong></h3><ul>
<li>케라스를 이용한 모델 구현</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">1</span>, input_dim=<span class="number">4</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_9&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_8 (Dense)              (None, 1)                 5         
=================================================================
Total params: 5
Trainable params: 5
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<ul>
<li>학습 파라미터 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">W = model.get_weights()[<span class="number">0</span>]</span><br><span class="line">b = model.get_weights()[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;W:&#x27;</span>,W,<span class="string">&#x27;b:&#x27;</span>,b)</span><br></pre></td></tr></table></figure>

<pre><code>W: [[ 0.6756476 ]
 [-0.5556424 ]
 [-0.47744548]
 [ 0.00187528]] b: [0.]
</code></pre>
<ul>
<li>시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Y_pred = model.predict(X)</span><br><span class="line"><span class="built_in">print</span>(Y.shape, Y_pred.shape)</span><br><span class="line"></span><br><span class="line">plt.plot(Y, linestyle=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.plot(Y_pred, linestyle=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:5 out of the last 9 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x7fd4582275f0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
(10,) (10, 1)
</code></pre>
<p><img src="output_42_1.png" alt="png"></p>
<h3 id="모델-학습"><a href="#모델-학습" class="headerlink" title="모델 학습"></a><strong>모델 학습</strong></h3><ul>
<li>모델 컴파일</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.SGD(learning_rate=<span class="number">0.01</span>),</span><br><span class="line">              loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;acc&#x27;</span>]</span><br><span class="line">              )</span><br></pre></td></tr></table></figure>

<ul>
<li>학습 진행</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(X, Y, epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<pre><code>1/1 [==============================] - 0s 4ms/step - loss: 0.1359 - acc: 1.0000





&lt;keras.callbacks.History at 0x7fd460462450&gt;
</code></pre>
<h3 id="결과"><a href="#결과" class="headerlink" title="결과"></a><strong>결과</strong></h3><ul>
<li>학습 파라미터 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">W = model.get_weights()[<span class="number">0</span>]</span><br><span class="line">b = model.get_weights()[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;W:&#x27;</span>,W,<span class="string">&#x27;b:&#x27;</span>,b)</span><br></pre></td></tr></table></figure>

<pre><code>W: [[ 1.0008601 ]
 [-0.14521359]
 [-0.7228296 ]
 [ 0.33016428]] b: [-0.03003764]
</code></pre>
<ul>
<li>시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Y_pred = model.predict(X)</span><br><span class="line"><span class="built_in">print</span>(Y.shape, Y_pred.shape)</span><br><span class="line"></span><br><span class="line">plt.plot(Y, linestyle=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.plot(Y_pred, linestyle=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>(10,) (10, 1)
</code></pre>
<p><img src="output_52_1.png" alt="png"></p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="You Ji Hun"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">You Ji Hun</p><p class="is-size-6 is-block">Student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Daegu</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">5</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">13</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/YJiHun"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/YJiHun/YJH" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">YJH</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="https://github.com/YJiHun/YJH_Project" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">YJH_Project</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/DeepLearning/"><span class="level-start"><span class="level-item">DeepLearning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GitHub/"><span class="level-start"><span class="level-item">GitHub</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/GitHub/GitBlog/"><span class="level-start"><span class="level-item">GitBlog</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/MLP/"><span class="level-start"><span class="level-item">MLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Threading/"><span class="level-start"><span class="level-item">Threading</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-10-27T08:20:00.000Z">2021-10-27</time></p><p class="title"><a href="/2021/10/27/DeepLearning/Fashion_Mnist_dataset/6_Fashion_Mnist_dataset/">Fashion_Minist_dataset을 이용하여 딥러닝 공부</a></p><p class="categories"><a href="/categories/DeepLearning/">DeepLearning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-10-27T08:20:00.000Z">2021-10-27</time></p><p class="title"><a href="/2021/10/27/DeepLearning/CIFAR_dataset/6_CIFAR_dataset/">Cifar10_dataset을 이용하여 딥러닝 공부</a></p><p class="categories"><a href="/categories/DeepLearning/">DeepLearning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-10-27T08:20:00.000Z">2021-10-27</time></p><p class="title"><a href="/2021/10/27/DeepLearning/Iris_dataset/%EA%B3%BC%EC%A0%9C1_Iris_dataset(%EC%A2%85%EB%A5%98%20%EC%98%88%EC%B8%A1)/">Iris_dataset을 이용하여 딥러닝 공부</a></p><p class="categories"><a href="/categories/DeepLearning/">DeepLearning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-10-27T03:20:00.000Z">2021-10-27</time></p><p class="title"><a href="/2021/10/27/DeepLearning/LogisticRegression/2_LogisticRegression/">딥러닝 공부를 해보자</a></p><p class="categories"><a href="/categories/DeepLearning/">DeepLearning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-10-23T05:52:53.000Z">2021-10-23</time></p><p class="title"><a href="/2021/10/23/Thread/Thread/">Threading을 해보자</a></p><p class="categories"><a href="/categories/Threading/">Threading</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">October 2021</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cifar10/"><span class="tag">Cifar10</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DNN/"><span class="tag">DNN</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DeepLearning/"><span class="tag">DeepLearning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Fashion-Minist/"><span class="tag">Fashion_Minist</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GitBlog/"><span class="tag">GitBlog</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GitHub/"><span class="tag">GitHub</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Iris/"><span class="tag">Iris</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Logistic-Regression/"><span class="tag">Logistic Regression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MLP/"><span class="tag">MLP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MNIST/"><span class="tag">MNIST</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Softmax-Regression/"><span class="tag">Softmax Regression</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Threading/"><span class="tag">Threading</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">지훈 블로그</a><p class="is-size-7"><span>&copy; 2021 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/YJiHun"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>